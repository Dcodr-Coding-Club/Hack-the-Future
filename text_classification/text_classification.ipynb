{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "BUSINESS          2000\n",
      "HEALTHY LIVING    2000\n",
      "MEDIA             2000\n",
      "POLITICS          2000\n",
      "SCIENCE           2000\n",
      "TECH              2000\n",
      "WELLNESS          2000\n",
      "WORLD NEWS        2000\n",
      "MONEY             1756\n",
      "U.S. NEWS         1377\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Apurav\\AppData\\Local\\Temp\\ipykernel_28348\\1072511818.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_balanced = df.groupby('category').apply(lambda x: x.sample(n=2000, random_state=42) if len(x) > 2000 else x).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('Filtered_News_Category_Dataset.json', lines=True)\n",
    "\n",
    "df_balanced = df.groupby('category').apply(lambda x: x.sample(n=2000, random_state=42) if len(x) > 2000 else x).reset_index(drop=True)\n",
    "\n",
    "# Save the balanced dataset\n",
    "# Show the new category distribution\n",
    "print(df_balanced['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Apurav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['headline'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "X = vectorizer.fit_transform(df['clean_text']).toarray()\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6378878878878879\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      BUSINESS       0.58      0.22      0.31      1788\n",
      "HEALTHY LIVING       0.43      0.07      0.12      1964\n",
      "         MEDIA       0.57      0.23      0.33       911\n",
      "         MONEY       0.54      0.24      0.33       552\n",
      "      POLITICS       0.81      0.84      0.82     10704\n",
      "       SCIENCE       0.54      0.23      0.32       640\n",
      "          TECH       0.67      0.32      0.43       643\n",
      "     U.S. NEWS       0.42      0.08      0.14       369\n",
      "      WELLNESS       0.48      0.90      0.62      5412\n",
      "    WORLD NEWS       0.55      0.24      0.33       993\n",
      "\n",
      "      accuracy                           0.64     23976\n",
      "     macro avg       0.56      0.34      0.38     23976\n",
      "  weighted avg       0.64      0.64      0.60     23976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDIA\n"
     ]
    }
   ],
   "source": [
    "def predict_category(text):\n",
    "    text = preprocess_text(text)\n",
    "    vectorized_text = vectorizer.transform([text]).toarray()\n",
    "    pred = model.predict(vectorized_text)\n",
    "    return encoder.inverse_transform(pred)[0]\n",
    "\n",
    "print(predict_category(\"i have world news\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset size: (11756, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Apurav\\AppData\\Local\\Temp\\ipykernel_28348\\569408614.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_balanced = df_filtered.groupby('category').apply(lambda x: x.sample(n=min(2000, len(x)), random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('News_Category_Dataset_v3.json', lines=True)\n",
    "\n",
    "selected_categories = [\"WELLNESS\", \"BUSINESS\", \n",
    "                       \"MEDIA\", \"SCIENCE\", \"TECH\", \"MONEY\"]\n",
    "df_filtered = df[df['category'].isin(selected_categories)]\n",
    "\n",
    "df_balanced = df_filtered.groupby('category').apply(lambda x: x.sample(n=min(2000, len(x)), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "print(\"Balanced dataset size:\", df_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Apurav\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_path = r\"C:\\Users\\Apurav\\OneDrive\\Desktop\\Project_ML\\Cold_email_generator\\models\\all-MiniLM-L6-v2\"\n",
    "embedding_model = SentenceTransformer(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5bd847ffcd44c19e43971c3af2e8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/598 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = embedding_model.encode(df_balanced['headline'].tolist(), batch_size=32, show_progress_bar=True)\n",
    "\n",
    "X = np.array(embeddings)\n",
    "y = df_balanced['category']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19133, 384)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "clf = XGBClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONEY\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(text):\n",
    "    \"\"\"Generate sentence embedding using SentenceTransformers.\"\"\"\n",
    "    return embedding_model.encode(text)\n",
    "\n",
    "def predict_category(text):\n",
    "    \"\"\"Predict category using the trained classifier with SentenceTransformers embeddings.\"\"\"\n",
    "    text_embedding = get_embedding(text).reshape(1, -1)\n",
    "    pred = clf.predict(text_embedding)\n",
    "    return le.inverse_transform(pred)[0]\n",
    "\n",
    "print(predict_category(\"my pin is 1213\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Predicted Category': 'HEALTHY LIVING', 'Suggested Encryption Algorithm': 'AES-256', 'Vulnerability Considerations': 'Privacy leaks'}\n"
     ]
    }
   ],
   "source": [
    "encryption_mapping = {\n",
    "    \"POLITICS\": (\"AES-256\", \"Targeted attacks, espionage\"),\n",
    "    \"WELLNESS\": (\"AES-GCM\", \"Medical data breaches\"),\n",
    "    \"HEALTHY LIVING\": (\"AES-256\", \"Privacy leaks\"),\n",
    "    \"BUSINESS\": (\"RSA-4096\", \"Financial fraud\"),\n",
    "    \"WORLD NEWS\": (\"AES-128\", \"Data integrity, spoofing\"),\n",
    "    \"MEDIA\": (\"RSA-2048\", \"Piracy, data leakage\"),\n",
    "    \"SCIENCE\": (\"ECC-256\", \"Intellectual property theft\"),\n",
    "    \"TECH\": (\"SHA-3 + ECC\", \"Cyber threats, hacking\"),\n",
    "    \"MONEY\": (\"AES-256 + HMAC\", \"Banking data theft\"),\n",
    "}\n",
    "\n",
    "def get_encryption_recommendation(category):\n",
    "    \"\"\"Get suggested encryption algorithm and vulnerabilities based on category.\"\"\"\n",
    "    return encryption_mapping.get(category, (\"Unknown\", \"No known vulnerabilities\"))\n",
    "\n",
    "def predict_and_recommend(text):\n",
    "    \"\"\"Predict category and provide encryption + vulnerability considerations.\"\"\"\n",
    "    predicted_category = predict_category(text)  # Get category from ML model\n",
    "    encryption, vulnerability = get_encryption_recommendation(predicted_category)\n",
    "    \n",
    "    return {\n",
    "        \"Predicted Category\": predicted_category,\n",
    "        \"Suggested Encryption Algorithm\": encryption,\n",
    "        \"Vulnerability Considerations\": vulnerability\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "result = predict_and_recommend(\"i am not feeling well\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model and vectorizer\n",
    "with open('text_classification.pkl', 'wb') as model_file:\n",
    "    pickle.dump(clf, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
