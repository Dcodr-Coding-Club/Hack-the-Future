{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Apurav\\Downloads\\hackTheFuture\\Hack-the-Future\\datasets\\crypto_dataset_large2.csv\"\n",
    "\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "# df['algorithm_label'] = label_encoder.fit_transform(df['Algorithm'])\n",
    "\n",
    "# Train-Test Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df['Ciphertext'], df['algorithm_label'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Algorithm\n",
       "DES         20000\n",
       "ChaCha20    20000\n",
       "ECC         20000\n",
       "Blowfish    20000\n",
       "RC4         20000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Algorithm\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_categories = [\"AES\", \"3DES\", \n",
    "                       \"RSA\", \"SHA-256\"]\n",
    "df_filtered = df[~df['Algorithm'].isin(selected_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Algorithm\n",
       "DES         20000\n",
       "ChaCha20    20000\n",
       "ECC         20000\n",
       "Blowfish    20000\n",
       "RC4         20000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[\"Algorithm\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['algorithm_label'] = label_encoder.fit_transform(df_filtered['Algorithm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algorithm_label\n",
       "2    20000\n",
       "1    20000\n",
       "3    20000\n",
       "0    20000\n",
       "4    20000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[\"algorithm_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_filtered['Ciphertext'], df_filtered['algorithm_label'], test_size=0.3, random_state=42)\n",
    "\n",
    "# import hashlib\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# # Feature extraction using character frequency and hashing\n",
    "# def extract_features(cipher_texts):\n",
    "#     vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "#     return vectorizer.fit_transform(cipher_texts)\n",
    "\n",
    "# X_train_features = extract_features(X_train)\n",
    "# X_test_features = extract_features(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000,), (30000,), (70000,), (30000,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 39) (30000, 39)\n",
      "Model Accuracy: 0.5841\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.45      0.41      5982\n",
      "           1       0.61      0.51      0.55      6060\n",
      "           2       0.38      0.43      0.41      5978\n",
      "           3       1.00      1.00      1.00      5994\n",
      "           4       0.63      0.53      0.58      5986\n",
      "\n",
      "    accuracy                           0.58     30000\n",
      "   macro avg       0.60      0.58      0.59     30000\n",
      "weighted avg       0.60      0.58      0.59     30000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2686  297 2682    1  316]\n",
      " [ 904 3077  830    1 1248]\n",
      " [2741  330 2590    1  316]\n",
      " [   0    0    0 5994    0]\n",
      " [ 759 1336  710    4 3177]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sys\n",
    "import os\n",
    "\n",
    "file = \"obfuscation\"\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(file), \"..\")))\n",
    "\n",
    "from obfuscation.obfuscation import obfuscate, deobfuscate\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# def convert_to_strings(feature_matrix):\n",
    "#     \"\"\" Converts a sparse or dense matrix to a list of strings. \"\"\"\n",
    "#     if isinstance(feature_matrix, csr_matrix):\n",
    "#         feature_matrix = feature_matrix.toarray()  # Convert sparse to dense\n",
    "\n",
    "#     return [\" \".join(map(str, row)) for row in feature_matrix]  # Convert row to string\n",
    "\n",
    "# # Convert training and testing features to strings\n",
    "# X_train_text = convert_to_strings(X_train_features)\n",
    "# X_test_text = convert_to_strings(X_test_features)\n",
    "\n",
    "# Now apply obfuscation\n",
    "# X_train_obfuscated = [obfuscate(text)[0] for text in X_train]\n",
    "# X_test_obfuscated = [obfuscate(text)[0] for text in X_test]\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_transformed.shape, X_test_transformed.shape)\n",
    "\n",
    "# Train model\n",
    "model2 = XGBClassifier(n_estimators=100, random_state=42)\n",
    "model2.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predict on obfuscated test data\n",
    "y_pred_obfuscated = model2.predict(X_test_transformed)\n",
    "\n",
    "# Deobfuscate predictions if necessary (not needed for numerical labels)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_obfuscated)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_obfuscated))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_obfuscated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 129) (30000, 129)\n",
      "Model Accuracy: 0.2022\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.43      0.26      5982\n",
      "           1       0.35      0.00      0.01      6060\n",
      "           2       0.22      0.27      0.25      5978\n",
      "           3       0.22      0.23      0.22      5994\n",
      "           4       0.17      0.08      0.11      5986\n",
      "\n",
      "    accuracy                           0.20     30000\n",
      "   macro avg       0.23      0.20      0.17     30000\n",
      "weighted avg       0.23      0.20      0.17     30000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2569   17 1696 1205  495]\n",
      " [2612   22 1809 1056  561]\n",
      " [2580   10 1643 1221  524]\n",
      " [3164    3  698 1355  774]\n",
      " [2617   10 1556 1327  476]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sys\n",
    "import os\n",
    "\n",
    "file = \"obfuscation\"\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(file), \"..\")))\n",
    "\n",
    "from obfuscation.obfuscation import obfuscate, deobfuscate\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# def convert_to_strings(feature_matrix):\n",
    "#     \"\"\" Converts a sparse or dense matrix to a list of strings. \"\"\"\n",
    "#     if isinstance(feature_matrix, csr_matrix):\n",
    "#         feature_matrix = feature_matrix.toarray()  # Convert sparse to dense\n",
    "\n",
    "#     return [\" \".join(map(str, row)) for row in feature_matrix]  # Convert row to string\n",
    "\n",
    "# # Convert training and testing features to strings\n",
    "# X_train_text = convert_to_strings(X_train_features)\n",
    "# X_test_text = convert_to_strings(X_test_features)\n",
    "\n",
    "# Now apply obfuscation\n",
    "X_test_obfuscated = [obfuscate(text)[0] for text in X_test]\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "X_all = np.concatenate((X_train, X_test_obfuscated), axis=0)  # Correct way\n",
    "\n",
    "vectorizer.fit(X_all)\n",
    "\n",
    "X_train_transformed = vectorizer.transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test_obfuscated)\n",
    "\n",
    "print(X_train_transformed.shape, X_test_transformed.shape)\n",
    "\n",
    "# Train model\n",
    "model2 = XGBClassifier(n_estimators=100, random_state=42)\n",
    "model2.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predict on obfuscated test data\n",
    "y_pred_obfuscated = model2.predict(X_test_transformed)\n",
    "\n",
    "# Deobfuscate predictions if necessary (not needed for numerical labels)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_obfuscated)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_obfuscated))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_obfuscated))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c\\x81\\x8d·\\x8dµÛ\\x9fu\\x93u\\x8bë¡×íÛÏ\\xadÑug\\x93oÝÛÃm\\x9f\\x91\\x99gé\\x93ica×\\x89\\x93§áÑggéáëÙcÉ£\\x91aõ¥«\\x9bÑ\\x9f\\x93£ÉË382404', 'Û\\x7fÉÇßéÑÏßw\\x93÷ï¥åçemScg\\x9bÏ¯Ã÷\\x9f¥\\x8dç\\xad¥©\\x89[¡µiå\\x8f\\x97ÏÇa\\x95·ñµ\\x99\\x81Ção±§oß£¯çmÑ\\x8f\\x9b¡¥ÑéÑßÍg\\x7fñ·\\x87030610', 'êpº\\x84ì¸â\\x9cºÆ\\x82b®Òf\\x8c¤þ\\x82\\x96Ô\\x88Ì\\x98æfØdjúîf¤xÎdºÈz¬\\x88Ô\\x82\\x86\\x8e®ÒÐ\\x94ÌÆ\\x8cÞ\\x94ª\\x9a¦ÜfÂjzäþª\\x9c\\x92¾ê\\x96\\x92¬Æh\\x80þh\\x9a¤¢h\\x86\\x8c\\xa0pfÐ\\x88677603', 'nâ¨nÜ\\x9e\\x80\\x92º¨\\xa0TÌÎÞxÀÚ\\x98èæ¦\\x90\\xa0ÚæÈf¢\\x82È\\x96¬\\x94\\x80¨hØìÎ\\\\¦ª®\\x9a\\x9cÞÎÖ®¸f®jÈ\\x98\\x88âÎæøèì\\xa0022709', 'úpd\\x8c\\x82\\x8câàÈªjàlÚú\\x84îèÌä\\x9aâfÞ\\xa0\\x96z\\x96xþ\\x84à\\x96Ò\\x8c\\x82¾øÈæÎ\\x80î¤\\x88ÀÔTÎªhîxÆ¢\\x90xþxÎþ\\x98¦ºTî\\\\ºpøÚä672917', '\\x9fÝ\\xadÙ\\x99\\x9b\\x9b\\x9b×ÝÃµÝÉ\\xadßËi\\x89\\x81ëõu©ÍçuÓÍáÛßõ\\x97å×\\x89©meÍ\\x87µ÷\\x9dÍ\\x93\\x9b©«ëµ\\x99\\x95é¯Áu\\x8fã\\x9fÝ\\x9dÇ172520', '\\x9cºb\\x98jTÀì¬¢¾\\x86¾\\x9elâøl`dx\\x8cn¢¤TÚ\\x82\\x86êhî¬\\x92¬\\x86îªºøÂÚÂ¬\\\\húî\\x80d\\x9c\\x92\\x9c¾þÐÌþnÆ\\x94z\\x80Ìââ\\x9e\\x94è\\x8cÚÈbèbþ325014', '·\\x7f§\\x97aÑ\\x83\\x9f\\x8fÉ÷w\\x95\\x9f\\x81ßíÕ¡ß\\x95ÑmÝÇw\\x97[\\x95\\x9f\\x8bÙñ·\\x83\\x93§Ýï\\x8b\\x83\\x95Ï\\x8d\\xad[[ñ¡gï\\x9b\\x95·Éáká\\x9fck«±±\\x7f\\x87¥\\x87371321', '\\x89\\x7f\\x8bkõß\\x97ßígk\\x91©Û\\x89oÓgc÷É\\x97ßw±¥\\x81k\\x95w«÷ë·c\\x97\\x8f\\x9fí\\x91ÙcÁiÓ·õ¥Óe\\x97Ý¥\\x9fë\\x9d¡ÁS«åí\\x97\\x8f£me\\x97Ï\\x9b\\x8b\\x9fÓÏ\\x81é220522', 'ÂpÎ¬\\x8eäÌl¾ÒÎÐ\\x8ehÌ\\x8c\\x86Ð¾ÐÂâÌºìæ¸Ð\\x86Ä\\x98nÒàÎ\\x84xà¸Ð®nÂº\\xa0êÂÐÚÄ\\x98\\x84hÒ¾\\x84¦æ\\x92\\x84pì¨Ä000412']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "\n",
    "file = \"obfuscation\"\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(file), \"..\")))\n",
    "from obfuscation.obfuscation import obfuscate, deobfuscate\n",
    "\n",
    "\n",
    "# Step 1: Apply obfuscation to test data\n",
    "X_test_obfuscated = [obfuscate(text)[0] for text in X_test] \n",
    "print(X_test_obfuscated[:10]) # Ensure obfuscation works on raw text\n",
    "all_text = list(df['Ciphertext']) + X_test_obfuscated  # Combine both\n",
    "all_chars = \"\".join(all_text) \n",
    "\n",
    "# print(all_chars[:100])  # Print first 100 characters for inspection\n",
    "char_counts = Counter(all_chars)\n",
    "char_vocab = sorted(char_counts.keys())  # Unique characters\n",
    "char_to_idx = {char: idx for idx, char in enumerate(char_vocab, start=1)}\n",
    "# print(f\"Vocabulary Size: {char_to_idx.keys()}\")\n",
    "\n",
    "# Function to convert ciphertext to sequence of numbers\n",
    "def text_to_sequence(text, max_len=100):\n",
    "    seq = [char_to_idx.get(char, 0) for char in text]\n",
    "    seq = seq[:max_len] + [0] * (max_len - len(seq))  # Pad/truncate to max_len\n",
    "    return seq\n",
    "\n",
    "# Step 2: Convert obfuscated text into numerical sequences\n",
    "X_train_seq = torch.tensor([text_to_sequence(text) for text in X_train], dtype=torch.long)\n",
    "X_test_seq_obfuscated = torch.tensor([text_to_sequence(text) for text in X_test_obfuscated], dtype=torch.long)\n",
    "\n",
    "# Step 3: Convert labels to tensors\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# # Convert all ciphertexts\n",
    "# X_train_seq = torch.tensor([text_to_sequence(text) for text in X_train], dtype=torch.long)\n",
    "# X_test_seq = torch.tensor([text_to_sequence(text) for text in X_test], dtype=torch.long)\n",
    "# y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "# y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from obfuscation.obfuscation import obfuscate  # Import the obfuscation function\n",
    "\n",
    "class EncryptionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.X[idx] is None or self.y[idx] is None:  # Debugging step\n",
    "            print(f\"Found None at index {idx}\")\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = EncryptionDataset(X_train_seq, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = EncryptionDataset(X_test_seq_obfuscated, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pickle\n",
    "\n",
    "class CipherLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, dropout_prob=0.5):\n",
    "        super(CipherLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        hidden = self.dropout(hidden[-1])  # Apply dropout before the fully connected layer\n",
    "        out = self.fc(hidden)\n",
    "        return out\n",
    "\n",
    "# Model parameters\n",
    "vocab_size = len(char_vocab) + 1  # Extra 1 for padding index\n",
    "embed_dim = 128\n",
    "hidden_dim = 256\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Initialize model\n",
    "model = CipherLSTM(vocab_size, embed_dim, hidden_dim, num_classes, dropout_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = r\"C:\\Users\\Apurav\\Downloads\\hackTheFuture\\Hack-the-Future\\models\\cipher_lstm_model.pth\"\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# # Set to evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_seq contains None: False\n",
      "y_train_tensor contains None: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_seq contains None: {any(x is None for x in X_train_seq)}\")\n",
    "print(f\"y_train_tensor contains None: {any(y is None for y in y_train_tensor)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.6378\n",
      "Epoch [2/3], Loss: 0.6320\n",
      "Epoch [3/3], Loss: 0.6309\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print loss every epoch\n",
    "    # if (epoch + 1) % 1 == 0:\n",
    "    #     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\Apurav\\Downloads\\hackTheFuture\\Hack-the-Future\\models\\cipher_lstm_model_after_obfuscation.pth\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "model_path = r\"C:\\Users\\Apurav\\Downloads\\hackTheFuture\\Hack-the-Future\\models\\cipher_lstm_model_after_obfuscation.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.1962\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5982\n",
      "           1       0.21      0.90      0.34      6060\n",
      "           2       0.06      0.00      0.00      5978\n",
      "           3       0.00      0.00      0.00      5994\n",
      "           4       0.43      0.07      0.12      5986\n",
      "\n",
      "    accuracy                           0.20     30000\n",
      "   macro avg       0.14      0.19      0.09     30000\n",
      "weighted avg       0.14      0.20      0.09     30000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   0 5916    6    0   60]\n",
      " [ 594 5465    0    0    1]\n",
      " [   0 5907   14    0   57]\n",
      " [1011 4450  119    0  414]\n",
      " [ 987 4512   79    0  408]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Apurav\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Apurav\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Apurav\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "\n",
    "        outputs = model(batch_X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print Classification Report (Precision, Recall, F1-score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions))\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Apurav\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_path = r\"C:\\Users\\Apurav\\OneDrive\\Desktop\\Project_ML\\Cold_email_generator\\models\\all-MiniLM-L6-v2\"\n",
    "embedding_model = SentenceTransformer(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882e34d1c6fd493ebf24732e86deeaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = embedding_model.encode(df_filtered['Ciphertext'].tolist(), batch_size=32, show_progress_bar=True)\n",
    "\n",
    "X = np.array(embeddings)\n",
    "y = df_filtered['algorithm_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train model\n",
    "model2 = XGBClassifier(n_estimators=100, random_state=42)\n",
    "model2.fit(X_train_features, y_train)\n",
    "\n",
    "\n",
    "# model = KNeighborsClassifier(n_neighbors=100)\n",
    "# model.fit(X_train_features, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model2.predict(X_test_features)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
